{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6b9da0f-1fbf-45cc-ace6-271aae54c8ae",
   "metadata": {},
   "source": [
    "#Â Finding a Model\n",
    "\n",
    "We start with imports and reading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2508c3b-9359-4054-a789-4079cc6ead52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203333, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10,000 B.C.</td>\n",
       "      <td>Actors</td>\n",
       "      <td>Steven Strait</td>\n",
       "      <td>D'Leh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10,000 B.C.</td>\n",
       "      <td>Actors</td>\n",
       "      <td>Camilla Belle</td>\n",
       "      <td>Evolet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10,000 B.C.</td>\n",
       "      <td>Actors</td>\n",
       "      <td>Cliff Curtis</td>\n",
       "      <td>Tic-Tic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10,000 B.C.</td>\n",
       "      <td>Actors</td>\n",
       "      <td>Reece Ritchie</td>\n",
       "      <td>Moha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10,000 B.C.</td>\n",
       "      <td>Actors</td>\n",
       "      <td>Marco Khan</td>\n",
       "      <td>One Eye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Movie    Type           Name     Role\n",
       "0  10,000 B.C.  Actors  Steven Strait    D'Leh\n",
       "1  10,000 B.C.  Actors  Camilla Belle   Evolet\n",
       "2  10,000 B.C.  Actors   Cliff Curtis  Tic-Tic\n",
       "3  10,000 B.C.  Actors  Reece Ritchie     Moha\n",
       "4  10,000 B.C.  Actors     Marco Khan  One Eye"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MultiLabelBinarizer, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from CustomExtractors import extract_numbers, extract_rating\n",
    "\n",
    "m_cast = pd.read_csv('./data/Movie Cast.csv')\n",
    "m_data = pd.read_csv('./data/Movie Data.csv')\n",
    "\n",
    "print(m_cast.shape)\n",
    "m_cast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2224bbf5-b937-4794-851d-b1b0545387a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5691, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Budget (thousands of $)</th>\n",
       "      <th>Domestic Box Office Revenue (thousands of $)</th>\n",
       "      <th>International Box Office Revenue (thousands of $)</th>\n",
       "      <th>MPAA Rating</th>\n",
       "      <th>Running time</th>\n",
       "      <th>Franchise</th>\n",
       "      <th>Original source</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Production method</th>\n",
       "      <th>Type</th>\n",
       "      <th>Production companies</th>\n",
       "      <th>Production country</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Distributor</th>\n",
       "      <th>Release year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Questions for the Dalai Lama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.5</td>\n",
       "      <td>260.0</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Life Events</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Live Action</td>\n",
       "      <td>Factual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>Monterey Media</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10th &amp; Wolf</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>54.7</td>\n",
       "      <td>89.1</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Life Events</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Live Action</td>\n",
       "      <td>Dramatization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>ThinkFilm</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006 Academy Award Nominated Short Films</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academy Award Short Film Nominations</td>\n",
       "      <td>Compilation</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Multiple Production Methods</td>\n",
       "      <td>Multiple Creative Types</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>Magnolia Pictures</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24 Hour Party People</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>2435.9</td>\n",
       "      <td>R for strong language, drug use and sexuality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Life Events</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Live Action</td>\n",
       "      <td>Dramatization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>MGM</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39 Pounds of Love</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Life Events</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Live Action</td>\n",
       "      <td>Factual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>Balcony Releasing</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Movie  Budget (thousands of $)  \\\n",
       "0           10 Questions for the Dalai Lama                      NaN   \n",
       "1                               10th & Wolf                   8000.0   \n",
       "2  2006 Academy Award Nominated Short Films                      NaN   \n",
       "3                      24 Hour Party People                      NaN   \n",
       "4                         39 Pounds of Love                      NaN   \n",
       "\n",
       "   Domestic Box Office Revenue (thousands of $)  \\\n",
       "0                                         224.5   \n",
       "1                                          54.7   \n",
       "2                                         335.1   \n",
       "3                                        1169.0   \n",
       "4                                          28.1   \n",
       "\n",
       "   International Box Office Revenue (thousands of $)  \\\n",
       "0                                              260.0   \n",
       "1                                               89.1   \n",
       "2                                                NaN   \n",
       "3                                             2435.9   \n",
       "4                                                2.1   \n",
       "\n",
       "                                     MPAA Rating Running time  \\\n",
       "0                                      Not Rated          NaN   \n",
       "1                                      Not Rated          NaN   \n",
       "2                                      Not Rated          NaN   \n",
       "3  R for strong language, drug use and sexuality          NaN   \n",
       "4                                      Not Rated          NaN   \n",
       "\n",
       "                              Franchise   Original source        Genre  \\\n",
       "0                                   NaN  Real Life Events  Documentary   \n",
       "1                                   NaN  Real Life Events        Drama   \n",
       "2  Academy Award Short Film Nominations       Compilation     Thriller   \n",
       "3                                   NaN  Real Life Events        Drama   \n",
       "4                                   NaN  Real Life Events  Documentary   \n",
       "\n",
       "             Production method                     Type Production companies  \\\n",
       "0                  Live Action                  Factual                  NaN   \n",
       "1                  Live Action            Dramatization                  NaN   \n",
       "2  Multiple Production Methods  Multiple Creative Types                  NaN   \n",
       "3                  Live Action            Dramatization                  NaN   \n",
       "4                  Live Action                  Factual                  NaN   \n",
       "\n",
       "  Production country Languages        Distributor  Release year  \n",
       "0      United States   English     Monterey Media          2007  \n",
       "1      United States   English          ThinkFilm          2006  \n",
       "2      United States   English  Magnolia Pictures          2007  \n",
       "3      United States   English                MGM          2002  \n",
       "4      United States   English  Balcony Releasing          2005  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m_data.shape)\n",
    "m_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cbbb960-3d3f-4610-a89c-b2197727a713",
   "metadata": {},
   "source": [
    "So I have a list of Staff with over 200k rows and also a list of movies with almost 6k rows. I need to combine this data somehow, including the staff into the data of each movie.\n",
    "\n",
    "The Target values would be **Total Box Office Revenue**, a sum of **Domestic** and **International Box Office Revenue**. This makes it a **Regression** problem.\n",
    "\n",
    "The models that we can try to approximate to data are:\n",
    "* Gradient descent (SGDRegressor & Lasso)\n",
    "* Random Forest\n",
    "* Boosted Trees\n",
    "\n",
    "In any case, before implementing the model we need to do some feature engineering, as there's a lot of missing data and columns which will clearly not have any effect (like **Role**).\n",
    "\n",
    "Finally, it would be smart to create some Dummy predictions so we can compare our models to it.\n",
    "\n",
    "But before anything, we need to split our data intro train/test, to avoid any data leakage when doing Feat. engineering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4f59eba-59fa-4079-99ff-cc8b311df1b6",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a414b44-f02a-4879-825f-ba13fa0f3489",
   "metadata": {},
   "source": [
    "We are not gonna split the `m_cast` data as it is just an extension for `m_data`. We already will select some movies to train the model on, and then we will take the data from the Cast & Crew of only the movies we've selected for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef96e40-aa8b-40f6-a601-cc3cf4a60b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        484.500\n",
       "1        143.800\n",
       "2        335.100\n",
       "3       3604.900\n",
       "4         30.200\n",
       "          ...   \n",
       "5686    1259.500\n",
       "5687      40.300\n",
       "5688      77.131\n",
       "5689      64.600\n",
       "5690    1944.300\n",
       "Length: 5691, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = [\n",
    "    'Domestic Box Office Revenue (thousands of $)', \n",
    "    'International Box Office Revenue (thousands of $)'\n",
    "]\n",
    "clean_target_cols = m_data[target_cols].fillna(0)\n",
    "y = clean_target_cols.iloc[:,0] + clean_target_cols.iloc[:,1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95470da0-633b-4370-9c72-a3b2238c7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = m_data.drop(target_cols, axis=1)\n",
    "\n",
    "# Divide data into training and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc2a073b-e032-447e-a0e1-e8e66f260d8a",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "642edf06-baae-4425-b515-00345008f756",
   "metadata": {},
   "source": [
    "Let's check the data from each column to see how to approach the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c2f386-9dbe-4c9a-b323-641c1729ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4993 rows have missing values in the train data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Movie                         0\n",
       "Budget (thousands of $)    2166\n",
       "MPAA Rating                   6\n",
       "Running time               1035\n",
       "Franchise                  4751\n",
       "Original source             170\n",
       "Genre                        11\n",
       "Production method           105\n",
       "Type                        226\n",
       "Production companies       1812\n",
       "Production country            6\n",
       "Languages                    30\n",
       "Distributor                  58\n",
       "Release year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans = X.shape[0] - X.dropna().shape[0]\n",
    "print (\"%d rows have missing values in the train data\" %nans)\n",
    "X.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faa38c9e-ff1e-46cc-8de7-b39c71d4557c",
   "metadata": {},
   "source": [
    "We see we can drop \"Franchise\" as it has too many rows without data.\n",
    "\n",
    "Then there is some data that will not be known previous to release, like \"Release year\", \"Distributor\" or \"MPAA Rating\" but they can be estimated (in case of Release and MPAA Rating) or, in the case of the Distributor, it can be inputed to check which one will give us more profits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea1b4c92-6411-4a32-acf9-1a93dd2dee80",
   "metadata": {},
   "source": [
    "### Excluded cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4824cc-0378-4294-a3e6-d65dc20db54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['Franchise']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb67fc84-7379-4529-a3cb-163b58f382d4",
   "metadata": {},
   "source": [
    "### Budget & Running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e27235-20ad-4452-824b-a16b60467bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie                       object\n",
       "Budget (thousands of $)    float64\n",
       "MPAA Rating                 object\n",
       "Running time                object\n",
       "Franchise                   object\n",
       "Original source             object\n",
       "Genre                       object\n",
       "Production method           object\n",
       "Type                        object\n",
       "Production companies        object\n",
       "Production country          object\n",
       "Languages                   object\n",
       "Distributor                 object\n",
       "Release year                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1034751e-d7db-44ff-a7b9-b779ae37d181",
   "metadata": {},
   "source": [
    "To work with NaN, in the case of Running time and Budget we should use the mean or median, but Running time is saved as a string, so we should change it to float (in minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f6bb83-8bc7-4a83-91f2-532f91c68daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '101 minutes', '100 minutes', '80 minutes', '90 minutes',\n",
       "       '107 minutes', '102 minutes', '140 minutes', '89 minutes',\n",
       "       '127 minutes', '95 minutes', '92 minutes', '119 minutes',\n",
       "       '110 minutes', '96 minutes', '109 minutes', '137 minutes',\n",
       "       '132 minutes', '105 minutes', '93 minutes', '124 minutes',\n",
       "       '70 minutes', '87 minutes', '99 minutes', '117 minutes',\n",
       "       '86 minutes', '82 minutes', '103 minutes', '79 minutes',\n",
       "       '88 minutes', '150 minutes', '125 minutes', '135 minutes',\n",
       "       '115 minutes', '133 minutes', '71 minutes', '114 minutes',\n",
       "       '97 minutes', '94 minutes', '116 minutes', '120 minutes',\n",
       "       '129 minutes', '81 minutes', '112 minutes', '108 minutes',\n",
       "       '118 minutes', '128 minutes', '84 minutes', '104 minutes',\n",
       "       '40 minutes', '98 minutes', '158 minutes', '146 minutes',\n",
       "       '91 minutes', '136 minutes', '190 minutes', '83 minutes',\n",
       "       '111 minutes', '138 minutes', '121 minutes', '164 minutes',\n",
       "       '123 minutes', '85 minutes', '113 minutes', '210 minutes',\n",
       "       '130 minutes', '122 minutes', '106 minutes', '131 minutes',\n",
       "       '159 minutes', '145 minutes', '44 minutes', '78 minutes',\n",
       "       '75 minutes', '74 minutes', '126 minutes', '42 minutes',\n",
       "       '39 minutes', '76 minutes', '134 minutes', '48 minutes',\n",
       "       '155 minutes', '175 minutes', '62 minutes', '172 minutes',\n",
       "       '139 minutes', '143 minutes', '160 minutes', '141 minutes',\n",
       "       '162 minutes', '189 minutes', '169 minutes', '144 minutes',\n",
       "       '201 minutes', '179 minutes', '153 minutes', '142 minutes',\n",
       "       '161 minutes', '152 minutes', '170 minutes', '148 minutes',\n",
       "       '72 minutes', '47 minutes', '157 minutes', '165 minutes',\n",
       "       '181 minutes', '156 minutes', '151 minutes', '77 minutes',\n",
       "       '231 minutes', '147 minutes', '154 minutes', '149 minutes',\n",
       "       '52 minutes', '68 minutes', '241 minutes', '46 minutes',\n",
       "       '73 minutes', '65 minutes', '43 minutes', '167 minutes',\n",
       "       '14 minutes', '61 minutes', '45 minutes', '398 minutes',\n",
       "       '187 minutes', '41 minutes', '69 minutes', '273 minutes',\n",
       "       '173 minutes', '195 minutes', '366 minutes', '194 minutes',\n",
       "       '182 minutes', '191 minutes', '25 minutes', '168 minutes',\n",
       "       '66 minutes', '257 minutes', '166 minutes', '184 minutes',\n",
       "       '240 minutes', '213 minutes', '180 minutes', '163 minutes',\n",
       "       '217 minutes', '220 minutes', '53 minutes', '174 minutes',\n",
       "       '188 minutes'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Running time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84fc4f6b-c4f2-4045-a148-a40ada75240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_extract_cols = ['Running time']\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "number_extractor_transformer = Pipeline(steps=[\n",
    "    ('extractor', FunctionTransformer(extract_numbers)),\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "num_cols = ['Budget (thousands of $)', 'Release year']\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8844ab08-1e0d-4d58-87b6-74fae01fbe2c",
   "metadata": {},
   "source": [
    "## Rating\n",
    "\n",
    "Now let's check string columns, starting with Rating. This is a perfect candidate for **ordinal encoding**. Let's check which values does it have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a507b008-e561-42d8-9a4c-5b258be6b7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Rated', 'R for strong language, drug use and sexuality',\n",
       "       'PG for thematic material, sensuality and language. ', ...,\n",
       "       'R for sequences of strong violence, language, some drug use and sexuality',\n",
       "       'R for pervasive strong violence and some sexual content',\n",
       "       'PG-13 for mature thematic material, sexual content and a rude gesture'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_col = ['MPAA Rating']\n",
    "\n",
    "X[rating_col[0]].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7318756-0dee-4a7b-a8b4-92bb0872043f",
   "metadata": {},
   "source": [
    "We just need the first string in the column data, the rest is unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98afc367-b7bc-4315-8e71-dbc31c355501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "R            2120\n",
       "PG-13        1765\n",
       "Not Rated     937\n",
       "PG            718\n",
       "G              99\n",
       "G(Rating       32\n",
       "NC-17           8\n",
       "Open            2\n",
       "GP              2\n",
       "PGPG            1\n",
       "M/PG            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[rating_col[0]].str.extract('(Not Rated|[^\\s]+)')[0].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d658206-7ac1-4274-a20b-9d9412e536ff",
   "metadata": {},
   "source": [
    "We find that we have cases besides the 5 current ratings (G, PG, PG-13, R, NC-17). With a bit of research we find that **GP** became PG. M was the previous iteration of PG, that's why *Z (1969)* (a great movie) has the **M/PG** rating, which should be transformed to PG. **PGPG** is a typo, as the movie is *E.T.*. The **G(Rating** ones just have the following format: *G(Rating bulletin XXXX, MM/DD/YYYY)*, so they should be G.\n",
    "\n",
    "Now, the two movies with **Open** have a bit more interesting stories. They were both released without rating as the directors disagreed with the rating given by the MPAA, which in both cases were NC-17, as it would've commercially killed the movies. For our model, we will be fair with the directors and give them both R ratings.\n",
    "\n",
    "For the NaN cases, we'll make them Not Rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee99ef5-10da-4681-a67c-72c94a1c33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_categories = [\n",
    "    'Not Rated',\n",
    "    'G',\n",
    "    'PG',\n",
    "    'PG-13',\n",
    "    'R',\n",
    "    'NC-17'\n",
    "];\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Not Rated')),\n",
    "    ('extractor', FunctionTransformer(extract_rating)),\n",
    "    ('encoder', OrdinalEncoder(categories=ratings_categories))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c1c4c83-7633-47ce-b465-fc9c33ed8317",
   "metadata": {},
   "source": [
    "### Other categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f9198e0-d42c-44a9-b116-657093a6f29f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original source\n",
      "Original Screenplay           2902\n",
      "Real Life Events               864\n",
      "Fiction Book/Short Story       857\n",
      "Remake                         211\n",
      "Comic/Graphic Novel            155\n",
      "Factual Book/Article           136\n",
      "TV                             120\n",
      "Play                            69\n",
      "Folk Tale/Legend/Fairytale      40\n",
      "Game                            35\n",
      "Spin-Off                        26\n",
      "Movie                           19\n",
      "Short Film                      18\n",
      "Musical or Opera                15\n",
      "Toy                             15\n",
      "Religious Text                  14\n",
      "Compilation                     11\n",
      "Theme Park Ride                  7\n",
      "Musical Group                    3\n",
      "Web Series                       2\n",
      "Ballet                           1\n",
      "Song                             1\n",
      "Name: count, dtype: int64\n",
      "Genre\n",
      "Drama              1743\n",
      "Comedy              931\n",
      "Thriller            616\n",
      "Adventure           572\n",
      "Action              545\n",
      "Documentary         475\n",
      "Horror              323\n",
      "Romantic Comedy     268\n",
      "Dark Comedy          74\n",
      "Musical              72\n",
      "Western              35\n",
      "Performance          25\n",
      "Reality               1\n",
      "Name: count, dtype: int64\n",
      "Production method\n",
      "Live Action                    5125\n",
      "Digital Animation               208\n",
      "Animation/Live Action           157\n",
      "Hand Animation                   67\n",
      "Stop-Motion Animation            20\n",
      "Multiple Production Methods       8\n",
      "Rotoscoping                       1\n",
      "Name: count, dtype: int64\n",
      "Type\n",
      "Contemporary Fiction       2823\n",
      "Historical Fiction          533\n",
      "Dramatization               515\n",
      "Factual                     498\n",
      "Science Fiction             356\n",
      "Fantasy                     333\n",
      "Kids Fiction                302\n",
      "Super Hero                   91\n",
      "Multiple Creative Types      14\n",
      "Name: count, dtype: int64\n",
      "Production companies\n",
      "Columbia Pictures                                                                                                                                                                                                                                                        16\n",
      "Participant Media                                                                                                                                                                                                                                                        16\n",
      "Working Title Films                                                                                                                                                                                                                                                      15\n",
      "Walt Disney Pictures                                                                                                                                                                                                                                                     15\n",
      "Marvel Studios                                                                                                                                                                                                                                                           14\n",
      "                                                                                                                                                                                                                                                                         ..\n",
      "Unified Pictures, Fawkes Partners, Rix Pix, Media House Capital, Nolan McDonald Films                                                                                                                                                                                     1\n",
      "Participant Media, di Bonaventura Pictures, Summit Entertainment, Closest to the Hole, Leverage                                                                                                                                                                           1\n",
      "Paramount Vantage, Grosvenor Park, Bedford Falls                                                                                                                                                                                                                          1\n",
      "Electric Eye Entertainment, Fathom Studios                                                                                                                                                                                                                                1\n",
      "Pharmachem, Apolo Media, Trice Films, Swiss Agency for Development and Cooperation SDC, Nature Conservation Programme in Macedonia, Project of the Swiss Agency for Cooperation and Development, Macedoniaâs Film Agency, SFFILM Documentary Film Fund, SFFILM Invest     1\n",
      "Name: count, Length: 3369, dtype: int64\n",
      "Production country\n",
      "United States                                         3992\n",
      "United Kingdom                                         178\n",
      "India                                                  157\n",
      "France                                                 138\n",
      "United Kingdom, United States                          137\n",
      "                                                      ... \n",
      "France, Ireland, Netherlands                             1\n",
      "France, Italy, Switzerland, United Kingdom               1\n",
      "France, Netherlands, United Kingdom, United States       1\n",
      "France, Romania, Spain, United States                    1\n",
      "Viet Nam                                                 1\n",
      "Name: count, Length: 363, dtype: int64\n",
      "Languages\n",
      "English                                       4590\n",
      "Hindi                                          128\n",
      "French                                         126\n",
      "Spanish                                         68\n",
      "English, Spanish                                58\n",
      "                                              ... \n",
      "English, French, German, Italian, Japanese       1\n",
      "English, French, German, Italian, Latin          1\n",
      "English, French, German, Polish                  1\n",
      "English, French, German, Spanish                 1\n",
      "Yiddish                                          1\n",
      "Name: count, Length: 276, dtype: int64\n",
      "Distributor\n",
      "Warner Bros.                           429\n",
      "Sony Pictures                          407\n",
      "Universal                              323\n",
      "20th Century Fox                       322\n",
      "Walt Disney                            284\n",
      "                                      ... \n",
      "Kino/Emerging                            1\n",
      "Motion Pictures Film and Television      1\n",
      "AMBI                                     1\n",
      "Wrekin Hill Entertainment                1\n",
      "Ficus                                    1\n",
      "Name: count, Length: 431, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns[5:-1]:\n",
    "    print(X[col].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e02b6687-da09-4077-a5b7-66c00c9b771e",
   "metadata": {},
   "source": [
    "Looks like **Languages**, **Production country** and **Production companies** need some O-H Encoding with the list of data they have. Distributor is complicated, because there are 431 different data! How to categorize it?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6b314f-2345-4d71-b627-faa4cf5bfe90",
   "metadata": {},
   "source": [
    "####Â Simple categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d384daf0-b310-40e6-8f8a-9c056420f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_simple = ['Original source', 'Genre', 'Production method', 'Type']\n",
    "\n",
    "simple_categorical_cols_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1dc4ea4-a78a-4d4b-84a9-3ec1dfebd6d7",
   "metadata": {},
   "source": [
    "#### MultiLabel columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69429d35-984a-4182-9e7a-6195c9bd6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_multilabel = ['Production companies', 'Production country', 'Languages']\n",
    "\n",
    "multilabel_categorical_cols_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', MultiLabelBinarizer())\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1be49e8f-4238-4636-b182-941afa500d85",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35940ff-f223-4588-bc1d-902608908fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_extract', number_extractor_transformer, num_extract_cols),\n",
    "        ('num', numerical_transformer, num_cols),\n",
    "        ('rating', ordinal_transformer, rating_col),\n",
    "        ('cat_simp', simple_categorical_cols_transformer, categorical_cols_simple),\n",
    "        ('cat_multi', multilabel_categorical_cols_transformer, categorical_cols_multilabel)\n",
    "    ])\n",
    "\n",
    "# Model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab808b9-9eb0-4934-8d8e-f1ecd72d07c4",
   "metadata": {},
   "source": [
    "## First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1748274e-bf1c-4b5a-a52b-cd69db26ae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R for language, some strong violence, and drug content']\n",
      " ['R for strong sexual content, nudity, language and brief drug use']\n",
      " ['PG for language, sexual situations, and some thematic material including partying (after editing, originally rated PG-13)']\n",
      " ...\n",
      " ['PG-13 for some sexuality and violence']\n",
      " ['PG for some rude humor, mild language and brief smoking(Rating bulletin 2103, 1/13/2010)']\n",
      " ['R for strong fantasy horror violence and gore, brief sexuality/nudity and language']]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m my_pipeline \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[1;32m      2\u001b[0m                               (\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m, model)\n\u001b[1;32m      3\u001b[0m                              ])\n\u001b[0;32m----> 5\u001b[0m my_pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[1;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    360\u001b[0m     cloned_transformer,\n\u001b[1;32m    361\u001b[0m     X,\n\u001b[1;32m    362\u001b[0m     y,\n\u001b[1;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:727\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m--> 727\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, y, _fit_transform_one)\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[1;32m    730\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:658\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    652\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    653\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[1;32m    654\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    655\u001b[0m     )\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    659\u001b[0m         delayed(func)(\n\u001b[1;32m    660\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[1;32m    661\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m    662\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    663\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m    664\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    665\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    669\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    670\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 437\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    439\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    360\u001b[0m     cloned_transformer,\n\u001b[1;32m    361\u001b[0m     X,\n\u001b[1;32m    362\u001b[0m     y,\n\u001b[1;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:238\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m    Transformed input.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, kw_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkw_args)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:310\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     func \u001b[39m=\u001b[39m _identity\n\u001b[0;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m func(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kw_args \u001b[39mif\u001b[39;49;00m kw_args \u001b[39melse\u001b[39;49;00m {}))\n",
      "File \u001b[0;32m~/Projects/Personal/python-learning/Movies/CustomExtractors.py:20\u001b[0m, in \u001b[0;36mextract_rating\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_rating\u001b[39m(data):\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mSeries(data)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mextract(\u001b[39m'\u001b[39m\u001b[39m(Not Rated|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]+)\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmap(__rating_equivalent)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:509\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    507\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    508\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    511\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    512\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/construction.py:569\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    567\u001b[0m subarr \u001b[39m=\u001b[39m data\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(data)\n\u001b[1;32m    571\u001b[0m \u001b[39mif\u001b[39;00m subarr \u001b[39mis\u001b[39;00m data \u001b[39mand\u001b[39;00m copy:\n\u001b[1;32m    572\u001b[0m     subarr \u001b[39m=\u001b[39m subarr\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1197\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1195\u001b[0m     \u001b[39m# Caller is responsible\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     \u001b[39mprint\u001b[39m(value)\n\u001b[0;32m-> 1197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(value\u001b[39m.\u001b[39mndim)  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(value):\n\u001b[1;32m   1200\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[0;31mValueError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "my_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4ee86-2532-4c81-9ca1-e928c8c0c060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
